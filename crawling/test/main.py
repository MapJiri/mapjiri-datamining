import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time
import requests  #  API ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ 
import boto3  # AWS SQS ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ 


sqs = boto3.client("sqs")
SQS_QUEUE_URL = "https://sqs.ap-northeast-2.amazonaws.com/182399700501/crawling_keyword"
API_URL = "http://13.124.190.196:8080/api/v1/restaurant/info"

def handler(event=None, context=None):
    # ğŸ“Œ SQS ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    response = sqs.receive_message(
        QueueUrl=SQS_QUEUE_URL,
        MaxNumberOfMessages=1,  
        WaitTimeSeconds=10  
    )
    # ğŸ“Œ ë©”ì‹œì§€ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬
    if "Messages" not in response:
        print("ğŸ“Œ ì²˜ë¦¬í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"statusCode": 400, "body": json.dumps("No messages to process")}

    # SQS ë©”ì‹œì§€ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    message = response["Messages"][0]
    receipt_handle = message["ReceiptHandle"]

    keyword_data = json.loads(message["Body"])  # {"dong": "ì˜¤ì •ë™", "keyword": "íŒŒìŠ¤íƒ€"}
    district = keyword_data.get("dong", "ê¸°ë³¸ë™")  # ê¸°ë³¸ê°’ ì„¤ì •
    menu = keyword_data.get("keyword", "ê¸°ë³¸ë©”ë‰´")
    


    # ì›¹ë“œë¼ì´ë²„ ì„¤ì •
    chrome_options = webdriver.ChromeOptions()
    chrome_options.binary_location = "/opt/chrome/chrome"
    chrome_options.add_argument("--headless")
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument("--single-process")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko")
    chrome_options.add_argument('window-size=1392x1150')
    chrome_options.add_argument("disable-gpu")
    chrome_options.add_argument("--start-maximized")
    service = Service(executable_path="/opt/chromedriver")

    driver = webdriver.Chrome(service=service, options=chrome_options)

    # ì¹´ì¹´ì˜¤ë§µ ì ‘ì†
    driver.get("https://map.kakao.com/")
    search_query = f"ëŒ€ì „ {district} {menu}"
    
    # ê²€ìƒ‰ ì‹¤í–‰
    input_tag = driver.find_element(By.ID, "search.keyword.query")
    input_tag.send_keys(search_query)
    input_tag.send_keys(Keys.RETURN)
    time.sleep(2)

    # 'ì¥ì†Œ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­
    try:
        more_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "info.search.place.more")))
        driver.execute_script("arguments[0].click();", more_button)
        time.sleep(3)
    except:
        pass

    # '1í˜ì´ì§€' ë²„íŠ¼ í´ë¦­
    try:
        first_page_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "info.search.page.no1")))
        driver.execute_script("arguments[0].click();", first_page_button)
        time.sleep(3)
    except:
        pass

    # í¬ë¡¤ë§ ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
    restaurants = []

    def scrape_restaurant():
        """ê°€ê²Œ ìƒì„¸ì •ë³´ í¬ë¡¤ë§"""
        try:
            driver.switch_to.window(driver.window_handles[1])

            # ê°€ê²Œ ì´ë¦„
            try:
                store_name = WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.XPATH, '//*[@id="mArticle"]/div[1]/div[1]/div[2]/div/h2'))
                ).text.strip()
            except:
                store_name = "ê°€ê²Œ ì •ë³´ ì—†ìŒ"

            # ê°€ê²Œ ì£¼ì†Œëª…
            try:
                place_name = WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.XPATH, '//*[@id="mArticle"]/div[1]/div[2]/div[1]/div/span[1]'))
                ).text.strip()
            except:
                place_name = "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"

            # ì¶”ì²œ í¬ì¸íŠ¸ í¬ë¡¤ë§
            try:
                tag_list = {}
                like_points = driver.find_elements(By.CSS_SELECTOR, ".view_likepoint .chip_likepoint")
                for point in like_points:
                    key = point.find_element(By.CLASS_NAME, "txt_likepoint").text.strip()
                    value = point.find_element(By.CLASS_NAME, "num_likepoint").text.strip()
                    tag_list[key] = value
            except:
                tag_list = {}

            # ëª¨ë“  ë¦¬ë·° í¬ë¡¤ë§
            reviews = []
            try:
                while True:
                    try:
                        # ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°
                        try:
                            more_button = driver.find_element(By.XPATH, '//*[@id="mArticle"]/div[8]/div[3]/a')
                        except:
                            try:
                                more_button = driver.find_element(By.XPATH, '//*[@id="mArticle"]/div[7]/div[3]/a')
                            except:
                                more_button = None

                        if more_button:
                            if "í›„ê¸° ì ‘ê¸°" in more_button.text:
                                break
                            driver.execute_script("arguments[0].click();", more_button)
                            time.sleep(2)
                        else:
                            break
                    except:
                        break

                review_elements = driver.find_elements(By.CSS_SELECTOR, "ul.list_evaluation > li")
                for review in review_elements[:50]:
                    try:
                        review_text = review.find_element(By.CLASS_NAME, "txt_comment").text
                        rating_style = review.find_element(By.CLASS_NAME, "inner_star").get_attribute("style")
                        rating = rating_style.split("width:")[1].replace("%;", "").strip()
                        date = review.find_element(By.CLASS_NAME, "time_write").text

                        # ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
                        try:
                            photo_element = review.find_element(By.CLASS_NAME, "list_photo").find_element(By.TAG_NAME, "img")
                            photo_url = photo_element.get_attribute("src")
                        except:
                            photo_url = None

                        reviews.append({
                            "reviewText": review_text,
                            "rating": rating,
                            "date": date,
                            "photoUrl": photo_url,
                        })
                    except:
                        continue
            except:
                reviews = None

            # ë°ì´í„° ì €ì¥
            restaurants.append({
                "name": store_name,
                "address": place_name,
                "tags": tag_list,
                "reviews": reviews
            })

            driver.close()
            driver.switch_to.window(driver.window_handles[0])
            time.sleep(2)

        except:
            driver.close()
            driver.switch_to.window(driver.window_handles[0])

    # ìµœëŒ€ í˜ì´ì§€ ìˆ˜ í™•ì¸
    try:
        pagination = driver.find_elements(By.XPATH, '//div[@id="info.search.page"]//a[contains(@id, "info.search.page.no")]')
        page_numbers = [int(p.text.strip()) for p in pagination if p.text.strip().isdigit()]
        max_page = max(page_numbers) if page_numbers else 1
    except:
        max_page = 1

    # ìµœëŒ€ 3í˜ì´ì§€ê¹Œì§€ë§Œ í¬ë¡¤ë§ ì œí•œ
    max_page = min(max_page, 3)

    # 1~max_page í˜ì´ì§€ í¬ë¡¤ë§
    for current_page in range(1, max_page + 1):
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.XPATH, '//*[@id="info.search.place.list"]/li'))
            )
            places = driver.find_elements(By.XPATH, '//*[@id="info.search.place.list"]/li')

            for place in places:
                try:
                    details_button = place.find_element(By.CLASS_NAME, "moreview")
                    driver.execute_script("arguments[0].click();", details_button)
                    time.sleep(3)
                    scrape_restaurant()
                except:
                    continue

            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            if current_page < max_page:
                try:
                    next_page_button = driver.find_element(By.ID, f"info.search.page.no{current_page + 1}")
                    driver.execute_script("arguments[0].click();", next_page_button)
                    time.sleep(3)
                except:
                    break
        except:
            break

    # ë“œë¼ì´ë²„ ì¢…ë£Œ
    driver.quit()

    # ğŸ“Œ API ìš”ì²­ ë°ì´í„° ìƒì„±
    request_body = {"list": restaurants}
    headers = {"Content-Type": "application/json"}

    # ğŸ“Œ API í˜¸ì¶œ
    try:
        response = requests.post(API_URL, headers=headers, json=request_body)
        response_data = response.json()
        print(f"ğŸ“Œ API ì‘ë‹µ: {response.status_code}, ë‚´ìš©: {response_data}")

            # ğŸ“Œ SQS ë©”ì‹œì§€ ì‚­ì œ (ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²½ìš°)
        sqs.delete_message(QueueUrl=SQS_QUEUE_URL, ReceiptHandle=receipt_handle)
        print(f"âœ… SQS ë©”ì‹œì§€ ì‚­ì œ ì™„ë£Œ: {district} - {menu}")

    except Exception as e:
        print(f"ğŸš¨ API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")

    # JSON ë°ì´í„° ì§ì ‘ ë°˜í™˜
    return {
        "statusCode": 200,
        "body": json.dumps(restaurants, ensure_ascii=False, indent=4)
    }

if __name__ == '__main__':
    handler()